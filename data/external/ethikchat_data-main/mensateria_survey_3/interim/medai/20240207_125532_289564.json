{"text": "Menschliche Entscheidungen basieren auch auf Erfahrungen und Daten. Also Ergebnissen aus vorherigen Operationen und Eingriffen. Die Maschine lernt auch aus vorliegenden Daten.\n\nJa, das ist richtig, aber Maschinen lernen nur aus den Daten, die ihnen zur Verfügung gestellt werden. Im Gegensatz dazu können Menschen neue Erkenntnisse gewinnen, indem sie ihre Erfahrungen mit anderen teilen und diskutieren. Diese Fähigkeit fehlt einer Maschine.\n\nGlaubst du nicht, dass KI irgendwann diese Fähigkeit entwickeln kann. Mir ist zwar bewusst, dass reine layerbasierte Modelle diese Fähigkeit nicht besitzen, aber vielleicht gelingt es uns mit genug Forschung das auch zu bewerkstelligen.\n\nDas ist möglich, aber aktuell ist es noch Zukunftsmusik. Selbst wenn wir es irgendwann erreichen, gibt es immer noch ethische Bedenken, die berücksichtigt werden müssen. Zum Beispiel, wie entscheidet eine KI, welche Informationen wichtig sind und welche nicht? Und wie gewährleisten wir, dass die KI nicht durch Vorurteile oder Fehler in den Trainingsdaten beeinflusst wird?\n\nDie Maschine weiß welche Entscheidungen richtig sind anhand einer Trends wie andere Ärzte davor entschieden haben. Man kann ja nicht davon ausgehen, dass jeder Arzt von Vorurteilen und Fehlern geprägt ist. Wenn man davon ausgeht, dass die Mehrheit saubere Entscheidungen trifft und diese dann in das Training von KI mit einfließen sehe ich keine Bedenken.\n\nAber was ist mit neuen, noch unbekannten Krankheiten oder seltenen Fällen, die in den Trainingsdaten nicht oder nur selten vorkommen? In solchen Fällen könnte eine KI, die nur anhand von Trends in den Trainingsdaten entscheidet, versagen. Auch wenn die Mehrheit der Ärzte frei von Vorurteilen ist, können sich diese in den Trainingsdaten verstecken und so die KI beeinflussen.\n\nDem Argument stimme ich zu. Aber wie schon oben gemeint, ich glaube dass künstliche Maschinen irgendwann auch die Fähigkeit besitzen könnten, Wissen zu abstrahieren und anzuwenden. So würden individuelle Entscheidungen möglich gemacht werden.\n\nAber auch dann bleibt die Frage, wie die Maschine entscheidet, welches Wissen abstrahiert und angewandt wird. Es gibt oft keine klaren Antworten in der Medizin, und Ärzte treffen Entscheidungen aufgrund einer Kombination aus Fakten, Erfahrungen, Werten und Intuition. Eine Maschine könnte diese Nuancen nicht verstehen.\n\nJa aber was wird das kleinere Übel sein, ein Arzt der auf sein Bauchgefühl hört oder eine Maschine die sich nicht sicher ist. Vielleicht liegt der Schlüssel auch darin, dass die Maschinen mit menschlichem Einfluss trainiert werden müssen. So könnten abstrakte Fälle den Ärzten gestellt werden und die Fakten, Erfahrungen, Werte und Intuition der Ärzte in das Modell mit einfließen. \n\nAber das führt uns zurück zum Ausgangspunkt, dass die KI dann doch die Entscheidungen des Menschen unterstützt, was nicht das Szenario ist, das wir diskutieren. Selbst wenn die KI mit menschlichem Einfluss trainiert wird, gibt es immer noch das Risiko, dass die KI in Situationen versagt, in denen die menschliche Intuition und Erfahrung nicht ausreichend berücksichtigt wurden.\n\nNein es wird doch trainiert anhand menschlichem Einfluss (genauso wie der Lehrling sich auch von seinem Meister ausbilden lässt). Die voll trainierte Maschine trifft dann schlussendlich doch die Entscheidung selbstständig.\n\nAber auch wenn die Maschine selbstständig entscheidet, basiert ihre Entscheidung immer noch auf dem, was sie im Training gelernt hat. Wenn also die Trainingsdaten nicht alle Eventualitäten abdecken, könnte die Maschine in bestimmten Situationen fehlschlagen. Im Gegensatz dazu können Menschen ihre Entscheidungen anpassen und neu bewerten, wenn sie neue Informationen erhalten.\n\nJa ich verstehe das schon alles. Ich glaube ich ändere meine Meinung. Ich glaube nun, dass das mit dem heutigen Stand der Technik mit unseren heutigen Modellen für KI nicht möglich ist.\n\nDas ist verständlich und eine kluge Einsicht. Es ist wichtig, die Möglichkeiten und Grenzen der aktuellen KI-Technologie zu verstehen. Auch wenn die KI in Zukunft möglicherweise in der Lage sein wird, unabhängige diagnostische und therapeutische Entscheidungen zu treffen, gibt es immer noch ethische Bedenken, die berücksichtigt werden müssen.\n\n", "annotations": [{"begin": 0, "end": 175, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 0, "user": "C2BYH", "timestamp": "2024/02/07-12:57:31"}}, {"begin": 177, "end": 442, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 1, "user": "GenBot", "timestamp": "2024/02/07-12:57:34"}}, {"begin": 444, "end": 680, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 2, "user": "C2BYH", "timestamp": "2024/02/07-12:58:41"}}, {"begin": 682, "end": 1056, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 3, "user": "GenBot", "timestamp": "2024/02/07-12:58:48"}}, {"begin": 1058, "end": 1413, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 4, "user": "C2BYH", "timestamp": "2024/02/07-13:01:05"}}, {"begin": 1415, "end": 1791, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 5, "user": "GenBot", "timestamp": "2024/02/07-13:01:10"}}, {"begin": 1793, "end": 2035, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 6, "user": "C2BYH", "timestamp": "2024/02/07-13:02:34"}}, {"begin": 2037, "end": 2356, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 7, "user": "GenBot", "timestamp": "2024/02/07-13:02:39"}}, {"begin": 2358, "end": 2740, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 8, "user": "C2BYH", "timestamp": "2024/02/07-13:04:55"}}, {"begin": 2742, "end": 3120, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 9, "user": "GenBot", "timestamp": "2024/02/07-13:05:02"}}, {"begin": 3122, "end": 3344, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 10, "user": "C2BYH", "timestamp": "2024/02/07-13:06:04"}}, {"begin": 3346, "end": 3723, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 11, "user": "GenBot", "timestamp": "2024/02/07-13:06:13"}}, {"begin": 3725, "end": 3910, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 12, "user": "C2BYH", "timestamp": "2024/02/07-13:08:16"}}, {"begin": 3912, "end": 4256, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 13, "user": "GenBot", "timestamp": "2024/02/07-13:08:21"}}, {"begin": 0, "end": 4258, "type": "de.uniwue.ethik-ki-chats.Dialogue", "features": {"name": "20240207_125532_289564", "szenario": "DialogueSzenario.STD_BOT", "start": "2024/02/07-12:55:32", "end": "2024/02/07-13:09:42"}}, {"begin": 0, "end": 4258, "type": "de.uniwue.ethik-ki-chats.StartSurvey", "features": {"name": "5ee1a9b7a2a85f115c822eb2b7171cdd", "agreement": 0.75, "informed": 0.25}}], "types": [{"name": "de.uniwue.ethik-ki-chats.Template", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}, {"name": "incorrect", "range": "RANGE_PRIMITIVE"}, {"name": "difficult", "range": "RANGE_PRIMITIVE"}, {"name": "multiple", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Introduction", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Transition", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Other", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Outro", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Dialogue", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "szenario", "range": "RANGE_PRIMITIVE"}, {"name": "start", "range": "RANGE_PRIMITIVE"}, {"name": "end", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.StartSurvey", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "agreement", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.EndSurvey", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "agreement", "range": "RANGE_PRIMITIVE"}, {"name": "opinion", "range": "RANGE_PRIMITIVE"}, {"name": "text_like", "range": "RANGE_PRIMITIVE"}, {"name": "text_dislike", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.UserUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.ExpertUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.BotUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}]}