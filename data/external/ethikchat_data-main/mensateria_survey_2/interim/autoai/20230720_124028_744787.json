{"text": "Ich denke, dass es problematisch ist, dass eine verantwortliche Person im Auto im Zweifelsfall nicht eingreifen kann. Eine Programmierung kann niemals perfekt sein, genauso wie ein Mensch. Es sollte aber möglich sein, dass ein Auto autonom fährt und im Falle eines Fehlers der Mensch den Fehler korrigieren kann, um Schlimmeres zu verhindern\n\nIch bin mir nicht sicher, was du meinst. Bitte wähle aus der folgenden Liste ein Argument aus, das deinen Standpunkt am besten repräsentiert. | Das technische System könnte versagen. |   Das mag sein. Neue erkenntnisse sowie auch Feher der autoKI können direkt weitergegeben werden, sodass aus ihren gelernt wird und etwaige Fehler nicht wieder passieren. Macht ein Mensch jedoch ein Fehler, lernt bestenfalls nur er dazu und begeht diesen kein weiteres Mal.  \n\nJa, das stimmt und ist tatsächlich besser als, wenn nur ein Mensch fährt. Trotzdem sollte ein Mensch die letzte Entscheidung haben. In so einem Fall könnte der Eingriff protokolliert werden und der Fahrer nachgefragt werden, was genau passiert ist\n\nIch bin mir nicht sicher, was du meinst. Bitte wähle aus der folgenden Liste ein Argument aus, das deinen Standpunkt am besten repräsentiert. | Menschenleben sollten nicht von einer KI abhängig sein. |   Das verstehe ich. Die autoKI erkennt die eigenen Systemgrenzen und wird bei deren Erreichen oder etwaiger technischer Störungen, die eine Ausübung der autonomen Fahrfunktion behindern, das Fahrzeug eigenständig in einen risikominimalen Zustand versetzen, bspw. auf einem Seitenstreifen zum Stehen kommen.  \n\nAber auch dieses Erkennungssystem kann versagen.\n\n Kurz zusammengefasst, Das technische System könnte versagen. Dem würde ich zustimmen. Aber zu beachten ist: Die soziale Inklusion kann gestärkt werden, denn der Einsatz fahrerloser Fahrzeuge unterstützt mobilitätseingeschränkte Personen bei der Teilhabe an der Mobilität und damit am gesellschaftlichen Leben insgesamt.\n\nJa, schon. Letztendlich bleiben aber immernoch Menschenleben gefährdet durch den Einsatz von solchen Fahrzeugen\n\n Du sagst, dass Das technische System versagen könnte. Ich denke damit liegst du richtig. Aber hast Du schon einmal daran gedacht: Die autoKI kann die Lenk-, Fahr- und Parkaufgabe präziser ausführen, weshalb Zusatzbreiten bei Fahrstreifen eingespart werden können. Auch beim Parken ergeben sich Vorteile und Stellplätze können schmaler werden, da kein Raum für sich öffnende Türen eingeplant werden muss. Zusatzbreiten bei Fahrstreifen könnten eingespart werden, was wiederum Platz für andere Verkehrsmittel oder Infrastruktur schaffen würde.\n\nStimmt. Und das sind alles Optimierungen, die sehr gut sind. An diesen Stellen hilft die KI dem Menschen, wo er nicht mehr diese Leistung erbringen kann. Trotzdem sollte der Mensch genauso die Maschine unterstützen können, wie sie den Menschen \n\nIch bin mir nicht sicher, was du meinst. Bitte wähle aus der folgenden Liste ein Argument aus, das deinen Standpunkt am besten repräsentiert. | Ich stimme deiner Argumentation zu. |   Schön, dass du mein Argument gut findest.   Aber zu beachten ist: Striktere Geschwindigkeitsbegrenzungen haben in Kombination mit den leistungsstarken autonomen Fahrsystemen die Folge, dass der Verkehr insgesamt sicherer wird, auch für sonstige Verkehrsteilnehmer.\n\nStimmt, ich sehe da auch ein großes Potenzial. Mein Einwand bleibt aber…\n\n Mit anderen Worten, langsames Fahren frustriert andere Verkehrsteilnehmer. Ich denke damit liegst du richtig. Um auch noch einmal eine andere Seite zu beleuchten: Die autoKI kann viel rascher und zielführender in kritischen Situationen entscheiden. Sie reagiert schneller in Gefahrensituationen und benötigt, anders als der Mensch, keine Reaktionszeit, um überhaupt erst zu handeln. Zudem lässt sich die autoKI nicht ablenken.\n\n", "annotations": [{"begin": 0, "end": 341, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 0, "user": "A8L1", "timestamp": "2023/07/20-12:43:48"}}, {"begin": 0, "end": 341, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 343, "end": 803, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 1, "user": "EthiBot", "timestamp": "2023/07/20-12:43:48"}}, {"begin": 343, "end": 803, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 805, "end": 1052, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 2, "user": "A8L1", "timestamp": "2023/07/20-12:46:46"}}, {"begin": 805, "end": 1052, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C14"}}, {"begin": 1054, "end": 1564, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 3, "user": "EthiBot", "timestamp": "2023/07/20-12:46:47"}}, {"begin": 1054, "end": 1564, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C14"}}, {"begin": 1566, "end": 1614, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 4, "user": "A8L1", "timestamp": "2023/07/20-12:48:18"}}, {"begin": 1566, "end": 1614, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 1616, "end": 1936, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 5, "user": "EthiBot", "timestamp": "2023/07/20-12:48:18"}}, {"begin": 1616, "end": 1638, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_24"}}, {"begin": 1638, "end": 1677, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 1677, "end": 1702, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_4"}}, {"begin": 1702, "end": 1724, "type": "de.uniwue.ethik-ki-chats.Transition", "features": {"label": "z_trans_12"}}, {"begin": 1724, "end": 1936, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.P6"}}, {"begin": 1938, "end": 2049, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 6, "user": "A8L1", "timestamp": "2023/07/20-12:49:14"}}, {"begin": 1938, "end": 2049, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 2051, "end": 2593, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 7, "user": "EthiBot", "timestamp": "2023/07/20-12:49:15"}}, {"begin": 2051, "end": 2066, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_27"}}, {"begin": 2066, "end": 2105, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C3"}}, {"begin": 2105, "end": 2140, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_5"}}, {"begin": 2140, "end": 2181, "type": "de.uniwue.ethik-ki-chats.Transition", "features": {"label": "z_trans_2"}}, {"begin": 2181, "end": 2593, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.P7"}}, {"begin": 2595, "end": 2839, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 8, "user": "A8L1", "timestamp": "2023/07/20-12:52:16"}}, {"begin": 2595, "end": 2839, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "UserAgrees"}}, {"begin": 2841, "end": 3289, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 9, "user": "EthiBot", "timestamp": "2023/07/20-12:52:16"}}, {"begin": 2841, "end": 3289, "type": "de.uniwue.ethik-ki-chats.Other", "features": {"label": ""}}, {"begin": 3291, "end": 3363, "type": "de.uniwue.ethik-ki-chats.UserUtterance", "features": {"id_in_dialogue": 10, "user": "A8L1", "timestamp": "2023/07/20-12:53:27"}}, {"begin": 3291, "end": 3363, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C2-1-1"}}, {"begin": 3365, "end": 3792, "type": "de.uniwue.ethik-ki-chats.BotUtterance", "features": {"id_in_dialogue": 11, "user": "EthiBot", "timestamp": "2023/07/20-12:53:28"}}, {"begin": 3365, "end": 3385, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_32"}}, {"begin": 3385, "end": 3440, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.C2-1-1"}}, {"begin": 3440, "end": 3475, "type": "de.uniwue.ethik-ki-chats.Introduction", "features": {"label": "intro_5"}}, {"begin": 3475, "end": 3528, "type": "de.uniwue.ethik-ki-chats.Transition", "features": {"label": "z_trans_13"}}, {"begin": 3528, "end": 3792, "type": "de.uniwue.ethik-ki-chats.Template", "features": {"label": "Z.P8"}}, {"begin": 0, "end": 3794, "type": "de.uniwue.ethik-ki-chats.Dialogue", "features": {"name": "20230720_124028_744787", "szenario": "DialogueSzenario.STD_BOT", "start": "2023/07/20-12:40:28", "end": "2023/07/20-12:56:07"}}, {"begin": 0, "end": 3794, "type": "de.uniwue.ethik-ki-chats.StartSurvey", "features": {"name": "b9f1dbd3a2e36515f43ad0993b4bc155", "agreement": 0.25, "informed": 0.5}}, {"begin": 0, "end": 3794, "type": "de.uniwue.ethik-ki-chats.EndSurvey", "features": {"name": "b9f1dbd3a2e36515f43ad0993b4bc155", "agreement": 0.25, "opinion": 0.5, "informative": 0.5, "text_like": "Der Bot hat neue Perspektiven auf das Thema aufgezeigt, an die ich vorher noch nicht gedacht hatte. ", "text_dislike": "Der Bot konnte relativ schlecht auf meine Argumente eingehen. Er hatte damit eher die Funktion einer intelligenteren Suchmaschine, als eines Gesprächspartners."}}], "types": [{"name": "de.uniwue.ethik-ki-chats.Template", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}, {"name": "incorrect", "range": "RANGE_PRIMITIVE"}, {"name": "difficult", "range": "RANGE_PRIMITIVE"}, {"name": "multiple", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Introduction", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Transition", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Other", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Outro", "features": [{"name": "label", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.Dialogue", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "szenario", "range": "RANGE_PRIMITIVE"}, {"name": "start", "range": "RANGE_PRIMITIVE"}, {"name": "end", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.StartSurvey", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "agreement", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.EndSurvey", "features": [{"name": "name", "range": "RANGE_PRIMITIVE"}, {"name": "agreement", "range": "RANGE_PRIMITIVE"}, {"name": "opinion", "range": "RANGE_PRIMITIVE"}, {"name": "text_like", "range": "RANGE_PRIMITIVE"}, {"name": "text_dislike", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.UserUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.ExpertUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}, {"name": "de.uniwue.ethik-ki-chats.BotUtterance", "features": [{"name": "id_in_dialogue", "range": "RANGE_PRIMITIVE"}, {"name": "user", "range": "RANGE_PRIMITIVE"}, {"name": "timestamp", "range": "RANGE_PRIMITIVE"}]}]}