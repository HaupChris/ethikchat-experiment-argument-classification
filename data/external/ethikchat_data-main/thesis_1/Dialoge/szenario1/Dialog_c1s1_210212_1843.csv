id, author, utterance, arg_label, arg_label, arg_label
18:43, 19:31
0, antonia.zierz.stud-mail, "KI ermöglicht es, dem demografischen Wandel in ländlichen Regionen zu begegnen. Die KI kann entlasten, besonders da, wo Fachkräfte knapp sind (auf dem Land, verstärkt durch die Überalterung der Gesellschaft).", pro_7
1, christian.hauptmann.stud-mail, "Der demografische Wandel führt aber auch zu einer immer älter werdenden Bevölkerung. Mögliche Fehler der KI würden in dieser Bevölkerungsgruppe vermutlich zu einem sehr großen Vertrauensverlust gegenüber der Technik führen.", pro_7.1.2
2, antonia.zierz.stud-mail, "Gerade aufgrund der älterwerdenden Bevölkerung gibt es aber immer größere Fluten an Bildern, die ausgewertet werden müssen. Das kann von Ärzten in Zukunft ohne technische Unterstützung gar nicht geleistet werden.", con_1.2, pro_13
3, christian.hauptmann.stud-mail, "Dadurch könnte es aber auch passieren, dass der überwiegende Anteil an Trainingsbeispielen für die KI von alten Menschen kommt und sich so Fehler bei jungen Menschen häufen.", con_15
4, antonia.zierz.stud-mail, "Die Trainingsbeispiele können ja aber variabel eingespielt werden. Das ist ja unabhängig davon, ob der Anwendungsbereich sich später zwangsläufig auf ältere Menschen konzentriert. Das ist ja der Vorteil der KI: viel größere Datenmengen abrufen zu können.", con_15.2
5, christian.hauptmann.stud-mail, "Bei so großen Datenmengen können sich aber unbemerkt Vorurteile einschleichen. (z.B. eine hohe Anzahl von Lungenerkrankungen, wenn in den Daten eine hohe Anzahl von Diagnosen von alten Menschen enthalten ist)", con_15.2.1
6, antonia.zierz.stud-mail, "Dem könnte man aber durch statistische Berechnungen im Vorfeld vorbeugen. Auch ein Arzt ist nicht frei von Vorurteilen.", con_15.2, con_15.1
7, christian.hauptmann.stud-mail, "Dem stimme ich zu. Nur wenn ein Arzt einen Fehler macht, haftet das Krankenhaus dafür. Wer übernimmt die Haftung für eine fehlerhafte KI?", con_15.1
8, antonia.zierz.stud-mail, "Man könnte Haftungsfonds einrichten. Auch eine Versicherungspflicht für die KI als eine elektronische Person mit Rechtspersönlichkeit käme in Frage.", con_5.1
9, christian.hauptmann.stud-mail, "Allerdings könnte eine fehlerhafte KI sich nicht erklären, wodurch unklar wäre, weshalb ein Fehler geschehen ist. Ärzte ermöglichen Nachvollziehbarkeit der Diagnosen.", con_2
10, antonia.zierz.stud-mail, "Eine fehlerhafte Entscheidung eines Arztes ist aber auch nicht immer nachvollziehbar, wenn z.B. einfach etwas übersehen wurde oder in der Hektik übergangen wurde.", con_2.6
11, christian.hauptmann.stud-mail, "Dann liegt aber der Grund in ungenauer Arbeit. Eine KI könnte bei zwei für Menschen sehr ähnlichen Beispielen das eine korrekt und das andere falsch diagnostizieren ohne für Menschen nachvollziehbare Gründe." exp_2
12, antonia.zierz.stud-mail, "Könnte das bei einem Arzt nicht genauso vorkommen? Dass er es bei eben einem Beispiel erkennt und ihm bei dem anderen gerade das entscheidende Wissensdetail fehlt?Bzw. ist mir nicht ganz klar, wieso die KI bei gleichgelagerten Kriterien dann zu unterschiedlichen Ergebnissen kommt und warum ein Fehler in diese Richtung nicht behebbar ist.", unk
13, christian.hauptmann.stud-mail, "Moderne Verfahren zur Bilderkennung arbeiten oft mit neuronalen Netzen. Durch das Training auf Beispieldaten lernen diese zwar wie ein bestimmtes Krankheitsbild aussieht, aber nicht, wie es nicht aussehen kann. Für Menschen ist so etwas völlig klar. Für die KI hingegen kann eine zufällig ungünstige Formation von Pixeln zu einer Diagnose führen, die komplett falsch ist. Dies wird durch mehr Trainingsdaten unwahrscheinlicher, ist jedoch nie mit kompletter Sicherheit auszuschließen.", exp_2.1
14, antonia.zierz.stud-mail, "Dann müsste ein Standard an Trainingsdaten verbindlich festgelegt werden. Eine absolute Sicherheit kann auch nicht durch einen Arzt gewährleistet werden.", con_15.2
